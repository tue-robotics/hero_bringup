<?xml version="1.0"?>
<launch>
<group ns="/hero">
<!-- launch julius speech recognition -->
<include file="$(find tmc_rosjulius)/launch/speech_recognition.launch"/>

<!-- Get the machine file -->
	<arg name="machine" default="localhost"/>
	<include file="$(env ROBOT_BRINGUP_PATH)/machines/$(arg machine).machine" />

<!-- always run a multicast server with a string topic answerer for amigo-hear -->
	<node name="hmi" pkg="hmi" type="multi_client" machine="$(arg machine)" output="log"/>

	<group ns="hmi">

		<!-- QR-code / amigo-hear -->
		<node name="string_topic_answerer" pkg="hmi" type="string_topic_answerer" output="log"/>

		<!-- If we are on the real robot, launch the server, otherwise a dummy -->
		<group if="$(optenv ROBOT_REAL false)">
			<!-- bridge to windows -->
			<node name="speech_recognition_bridge" pkg="hero_bridge" type="hmi_server_julius_client.py" machine="$(arg machine)" output="log">
				<rosparam command="load" file="$(env ROBOT_BRINGUP_PATH)/parameters/interaction/speech_client.yaml" />
			</node>
		</group>
		<group unless="$(optenv ROBOT_REAL false)">
			<!-- speech dummy -->
			<node name="random_answerer" pkg="hmi" type="random_answerer" machine="$(arg machine)" output="log"/>
			<node name="dragonfly_speech_recognition" pkg="hmi" type="dragonfly_restart_mock" machine="$(arg machine)" output="log"/>
		</group>

	</group> <!-- ns="hmi" -->
</group>
</launch>
